{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ĐỀ TÀI 9: PHÂN LOẠI NẤM (ĂN ĐƯỢC HAY ĐỘC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bước 1: Khám phá và Phân tích Dữ liệu (EDA)\n",
    "* Mục tiêu:\n",
    "  1. Hiểu cấu trúc và đặc điểm của dataset (số mẫu, số đặc trưng, kiểu dữ liệu).\n",
    "  2. Phân tích phân phối của biến mục tiêu ('class') để đánh giá mất cân bằng lớp (class imbalance).\n",
    "  3. Khám phá các đặc trưng phân loại (categorical) thông qua tần suất và biểu đồ để nhận diện các đặc trưng quan trọng.\n",
    "  4. Kiểm tra dữ liệu thiếu (missing values) và mối quan hệ giữa các đặc trưng với biến mục tiêu để xác định các vấn đề cần xử lý trong tiền xử lý.\n",
    "  5. Cung cấp cơ sở cho các bước tiếp theo (preprocessing, feature engineering) bằng cách xác định các đặc trưng có giá trị dự đoán cao và vấn đề dữ liệu (như missing values). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.idle": "2025-09-22T15:10:55.766161Z",
     "shell.execute_reply": "2025-09-22T15:10:55.765384Z",
     "shell.execute_reply.started": "2025-09-22T15:10:44.117561Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Thiết lập style cho biểu đồ\n",
    "sns.set(font_scale=1.2)\n",
    "\n",
    "# 1. Load dữ liệu\n",
    "train_df = pd.read_csv('Dataset\\\\train.csv')\n",
    "test_df = pd.read_csv('Dataset\\\\test.csv')\n",
    "\n",
    "# 2. Kiểm tra cấu trúc dữ liệu\n",
    "print(\"=== Cấu trúc Train Dataset ===\")\n",
    "print(f\"Số mẫu: {train_df.shape[0]}\")\n",
    "print(f\"Số đặc trưng (bao gồm target và id): {train_df.shape[1]}\")\n",
    "print(\"\\nKiểu dữ liệu các cột:\")\n",
    "print(train_df.dtypes)\n",
    "print(\"\\nThông tin tổng quan:\")\n",
    "print(train_df.info())\n",
    "\n",
    "print(\"\\n=== Cấu trúc Test Dataset ===\")\n",
    "print(f\"Số mẫu: {test_df.shape[0]}\")\n",
    "print(f\"Số đặc trưng (bao gồm target và id): {test_df.shape[1]}\")\n",
    "print(\"\\nKiểu dữ liệu các cột:\")\n",
    "print(test_df.dtypes)\n",
    "\n",
    "# 3. Phân tích biến mục tiêu (class)\n",
    "print(\"\\n=== Phân phối biến mục tiêu (class) trong Train ===\")\n",
    "print(train_df['class'].value_counts(normalize=True))\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='class', data=train_df)\n",
    "plt.title('Phân phối Class (Poisonous vs Edible) - Train')\n",
    "plt.xlabel('Class (e: Edible, p: Poisonous)')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig('class_distribution.png')\n",
    "plt.show()\n",
    "\n",
    "# 4. Phân tích đặc trưng\n",
    "# Chú thích: Không có đặc trưng số (numerical), chỉ có categorical\n",
    "print(\"\\n=== Chú thích ===\")\n",
    "print(\"Dataset không có đặc trưng số, do đó không thực hiện thống kê mô tả, histogram hoặc boxplot.\")\n",
    "\n",
    "# Phân tích đặc trưng phân loại\n",
    "categorical_cols = train_df.drop(columns=['class', 'id']).columns\n",
    "n_cols = 3  # Số cột trong lưới subplot\n",
    "n_rows = int(np.ceil(len(categorical_cols) / n_cols))\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*6, n_rows*5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(categorical_cols):\n",
    "    sns.countplot(x=col, hue='class', data=train_df, ax=axes[i])\n",
    "    axes[i].set_title(f'Phân phối {col} theo Class')\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel('Count')\n",
    "    axes[i].legend(title='Class', loc='upper right')\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Xóa các subplot trống\n",
    "for j in range(i+1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('categorical_features_distribution.png')\n",
    "plt.show()\n",
    "\n",
    "# 5. Phân tích dữ liệu thiếu (missing)\n",
    "print(\"\\n=== Phân tích dữ liệu thiếu (Train) ===\")\n",
    "missing_train = train_df.replace('?', np.nan).isnull().sum()\n",
    "print(missing_train[missing_train > 0])\n",
    "\n",
    "print(\"\\n=== Phân tích dữ liệu thiếu (Test) ===\")\n",
    "missing_test = test_df.replace('?', np.nan).isnull().sum()\n",
    "print(missing_test[missing_test > 0])\n",
    "\n",
    "# Phân tích missing theo class\n",
    "print(\"\\n=== Phân tích Missing theo Class (Train) ===\")\n",
    "missing_by_class = train_df[train_df['stalk-root'] == '?'].groupby('class').size()\n",
    "print(missing_by_class)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='stalk-root', hue='class', data=train_df[train_df['stalk-root'] == '?'])\n",
    "plt.title('Phân phối Missing Values (stalk-root) theo Class')\n",
    "plt.xlabel('stalk-root (Missing = ?)')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig('missing_stalk_root_by_class.png')\n",
    "plt.show()\n",
    "\n",
    "# 6. Phân tích mối quan hệ: Chi-square test thay cho ma trận tương quan\n",
    "print(\"\\n=== Phân tích mối quan hệ (Chi-square test) ===\")\n",
    "chi2_results = {}\n",
    "for col in categorical_cols:\n",
    "    contingency_table = pd.crosstab(train_df[col], train_df['class'])\n",
    "    chi2, p, _, _ = chi2_contingency(contingency_table)\n",
    "    chi2_results[col] = p\n",
    "\n",
    "# Chuyển kết quả chi-square thành DataFrame\n",
    "chi2_df = pd.DataFrame.from_dict(chi2_results, orient='index', columns=['p-value'])\n",
    "chi2_df = chi2_df.sort_values(by='p-value')\n",
    "\n",
    "# In kết quả\n",
    "print(\"\\nP-values từ Chi-square test (thấp hơn = đặc trưng quan trọng hơn):\")\n",
    "print(chi2_df)\n",
    "\n",
    "# Vẽ heatmap cho p-values\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(chi2_df, annot=True, cmap='coolwarm', fmt='.2e')\n",
    "plt.title('P-values của Chi-square Test giữa Đặc trưng và Class')\n",
    "plt.savefig('chi2_pvalues_heatmap.png')\n",
    "plt.show()\n",
    "\n",
    "# 7. Phân tích giá trị unique của các đặc trưng\n",
    "print(\"\\n=== Số giá trị unique của từng đặc trưng (Train) ===\")\n",
    "unique_counts = train_df.drop(columns=['id']).nunique()\n",
    "print(unique_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bước 2: Tiền xử lý và Kỹ thuật Đặc trưng (song song 2 luồng)\n",
    "* Mục tiêu chung:\n",
    "  1. Chuẩn bị dữ liệu sạch và phù hợp cho huấn luyện mô hình học máy, đảm bảo xử lý các vấn đề của dataset (missing values, categorical data) và tối ưu hóa đặc trưng để cải thiện hiệu suất mô hình.\n",
    "  2. Tạo hai bộ dữ liệu đặc trưng riêng biệt từ hai luồng:\n",
    "     * Luồng A: Sử dụng kỹ thuật truyền thống để xử lý dữ liệu và tạo đặc trưng thủ công.\n",
    "     * Luồng B: Sử dụng autoencoder để tự động trích xuất đặc trưng từ dữ liệu, tạo bộ đặc trưng mới từ lớp bottleneck."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Luồng A: Kỹ thuật Truyền thống\n",
    "* Mục tiêu:\n",
    "  1. Xử lý missing values: Thay '?' trong stalk-root bằng mode.\n",
    "  2. Mã hóa categorical: Sử dụng cả One-Hot Encoding (phiên bản chính) và Label Encoding (phiên bản bổ sung) để tạo hai bộ dữ liệu.\n",
    "  3. Chuẩn hóa/scale dữ liệu số: Bỏ qua (dataset không có dữ liệu số), thêm chú thích rõ ràng.\n",
    "  4. Feature engineering: Tạo thêm đặc trưng (kết hợp gill-color và spore-print-color, nhị phân hóa bruises).\n",
    "  5. Feature selection: Loại bỏ đặc trưng ít quan trọng dựa trên chi-square p-value từ EDA.\n",
    "  6. Kết quả: Tạo hai bộ dữ liệu:\n",
    "     * One-Hot: X_train_onehot.csv, X_test_onehot.csv, y_train_onehot.csv.\n",
    "     * Label Encoding: X_train_label.csv, X_test_label.csv, y_train_label.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T15:11:22.750482Z",
     "iopub.status.busy": "2025-09-22T15:11:22.749908Z",
     "iopub.status.idle": "2025-09-22T15:11:23.731960Z",
     "shell.execute_reply": "2025-09-22T15:11:23.731245Z",
     "shell.execute_reply.started": "2025-09-22T15:11:22.750454Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m chi2_contingency\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Kiểm tra cột trong test_df\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCột trong test_df:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlist\u001b[39m(\u001b[43mtest_df\u001b[49m.columns))\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# 1. Xử lý missing values\u001b[39;00m\n\u001b[32m     10\u001b[39m train_df[\u001b[33m'\u001b[39m\u001b[33mstalk-root\u001b[39m\u001b[33m'\u001b[39m] = train_df[\u001b[33m'\u001b[39m\u001b[33mstalk-root\u001b[39m\u001b[33m'\u001b[39m].replace(\u001b[33m'\u001b[39m\u001b[33m?\u001b[39m\u001b[33m'\u001b[39m, train_df[\u001b[33m'\u001b[39m\u001b[33mstalk-root\u001b[39m\u001b[33m'\u001b[39m].mode()[\u001b[32m0\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'test_df' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Kiểm tra cột trong test_df\n",
    "print(\"Cột trong test_df:\", list(test_df.columns))\n",
    "\n",
    "# 1. Xử lý missing values\n",
    "train_df['stalk-root'] = train_df['stalk-root'].replace('?', train_df['stalk-root'].mode()[0])\n",
    "test_df['stalk-root'] = test_df['stalk-root'].replace('?', test_df['stalk-root'].mode()[0])\n",
    "\n",
    "# 2. Loại bỏ cột không cần thiết\n",
    "columns_to_drop = ['veil-type', 'veil-color', 'id']\n",
    "columns_to_drop = [col for col in columns_to_drop if col in train_df.columns]\n",
    "train_df = train_df.drop(columns=columns_to_drop)\n",
    "test_df = test_df.drop(columns=[col for col in columns_to_drop if col in test_df.columns])\n",
    "\n",
    "# 3. Tách features và target\n",
    "X_train = train_df.drop('class', axis=1)\n",
    "y_train = train_df['class']\n",
    "X_test = test_df  # test_df không có cột 'class'\n",
    "\n",
    "# Chú thích: Không có đặc trưng số nên bỏ qua chuẩn hóa/scale\n",
    "print(\"Chú thích: Dataset không có đặc trưng số, bỏ qua bước chuẩn hóa/scale (StandardScaler, MinMaxScaler).\")\n",
    "\n",
    "# 4. Feature selection dựa trên chi-square test\n",
    "chi2_results = {}\n",
    "for col in X_train.columns:\n",
    "    contingency_table = pd.crosstab(X_train[col], y_train)\n",
    "    chi2, p, _, _ = chi2_contingency(contingency_table)\n",
    "    chi2_results[col] = p\n",
    "\n",
    "# Chọn đặc trưng có p-value < 0.05 (quan trọng)\n",
    "important_features = [col for col, p in chi2_results.items() if p < 0.05]\n",
    "print(\"Đặc trưng quan trọng (p-value < 0.05):\", important_features)\n",
    "\n",
    "# Lọc X_train và X_test chỉ giữ đặc trưng quan trọng\n",
    "X_train_onehot = X_train[important_features]\n",
    "X_test_onehot = X_test[important_features]\n",
    "\n",
    "# 5. Mã hóa categorical: One-Hot Encoding\n",
    "ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "X_train_onehot_encoded = ohe.fit_transform(X_train_onehot)\n",
    "X_test_onehot_encoded = ohe.transform(X_test_onehot)\n",
    "\n",
    "feature_names_onehot = ohe.get_feature_names_out(important_features)\n",
    "X_train_onehot_encoded = pd.DataFrame(X_train_onehot_encoded, columns=feature_names_onehot)\n",
    "X_test_onehot_encoded = pd.DataFrame(X_test_onehot_encoded, columns=feature_names_onehot)\n",
    "\n",
    "# 6. Feature engineering cho One-Hot\n",
    "# Tạo đặc trưng: odor + spore-print-color\n",
    "X_train_onehot_encoded['odor_spore_interaction'] = X_train['odor'] + '_' + X_train['spore-print-color']\n",
    "X_test_onehot_encoded['odor_spore_interaction'] = X_test['odor'] + '_' + X_test['spore-print-color']\n",
    "# Tạo đặc trưng: gill-color + spore-print-color\n",
    "X_train_onehot_encoded['gill_spore_interaction'] = X_train['gill-color'] + '_' + X_train['spore-print-color']\n",
    "X_test_onehot_encoded['gill_spore_interaction'] = X_test['gill-color'] + '_' + X_test['spore-print-color']\n",
    "# Nhị phân hóa bruises\n",
    "X_train_onehot_encoded['bruises_binary'] = X_train['bruises'].map({'f': 0, 't': 1})\n",
    "X_test_onehot_encoded['bruises_binary'] = X_test['bruises'].map({'f': 0, 't': 1})\n",
    "\n",
    "# Mã hóa các đặc trưng mới\n",
    "ohe_interaction = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "interaction_train = ohe_interaction.fit_transform(X_train_onehot_encoded[['odor_spore_interaction', 'gill_spore_interaction']])\n",
    "interaction_test = ohe_interaction.transform(X_test_onehot_encoded[['odor_spore_interaction', 'gill_spore_interaction']])\n",
    "\n",
    "interaction_feature_names = ohe_interaction.get_feature_names_out(['odor_spore_interaction', 'gill_spore_interaction'])\n",
    "X_train_onehot_encoded = pd.concat([X_train_onehot_encoded.drop(['odor_spore_interaction', 'gill_spore_interaction'], axis=1),\n",
    "                                    pd.DataFrame(interaction_train, columns=interaction_feature_names)], axis=1)\n",
    "X_test_onehot_encoded = pd.concat([X_test_onehot_encoded.drop(['odor_spore_interaction', 'gill_spore_interaction'], axis=1),\n",
    "                                   pd.DataFrame(interaction_test, columns=interaction_feature_names)], axis=1)\n",
    "\n",
    "# 7. Mã hóa categorical: Label Encoding\n",
    "X_train_label = X_train.copy()\n",
    "X_test_label = X_test.copy()\n",
    "label_encoders = {}\n",
    "for col in X_train_label.columns:\n",
    "    le = LabelEncoder()\n",
    "    X_train_label[col] = le.fit_transform(X_train_label[col])\n",
    "    X_test_label[col] = le.transform(X_test_label[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Feature engineering cho Label Encoding\n",
    "X_train_label['odor_spore_interaction'] = X_train['odor'] + '_' + X_train['spore-print-color']\n",
    "X_test_label['odor_spore_interaction'] = X_test['odor'] + '_' + X_test['spore-print-color']\n",
    "X_train_label['gill_spore_interaction'] = X_train['gill-color'] + '_' + X_train['spore-print-color']\n",
    "X_test_label['gill_spore_interaction'] = X_test['gill-color'] + '_' + X_test['spore-print-color']\n",
    "X_train_label['bruises_binary'] = X_train['bruises'].map({'f': 0, 't': 1})\n",
    "X_test_label['bruises_binary'] = X_test['bruises'].map({'f': 0, 't': 1})\n",
    "\n",
    "# Mã hóa các đặc trưng mới\n",
    "le_interaction = LabelEncoder()\n",
    "X_train_label['odor_spore_interaction'] = le_interaction.fit_transform(X_train_label['odor_spore_interaction'])\n",
    "X_test_label['odor_spore_interaction'] = le_interaction.transform(X_test_label['odor_spore_interaction'])\n",
    "le_gill_spore = LabelEncoder()\n",
    "X_train_label['gill_spore_interaction'] = le_gill_spore.fit_transform(X_train_label['gill_spore_interaction'])\n",
    "X_test_label['gill_spore_interaction'] = le_gill_spore.transform(X_test_label['gill_spore_interaction'])\n",
    "\n",
    "# Mã hóa target\n",
    "y_train = y_train.map({'e': 0, 'p': 1})\n",
    "\n",
    "# 8. Lưu dữ liệu\n",
    "X_train_onehot_encoded.to_csv('X_train_onehot.csv', index=False)\n",
    "X_test_onehot_encoded.to_csv('X_test_onehot.csv', index=False)\n",
    "X_train_label.to_csv('X_train_label.csv', index=False)\n",
    "X_test_label.to_csv('X_test_label.csv', index=False)\n",
    "y_train.to_csv('y_train.csv', index=False)\n",
    "\n",
    "print(\"=== Kết quả Luồng A ===\")\n",
    "print(f\"X_train_onehot shape: {X_train_onehot_encoded.shape}\")\n",
    "print(f\"X_test_onehot shape: {X_test_onehot_encoded.shape}\")\n",
    "print(f\"X_train_label shape: {X_train_label.shape}\")\n",
    "print(f\"X_test_label shape: {X_test_label.shape}\")\n",
    "print(f\"One-Hot Feature names: {list(X_train_onehot_encoded.columns)}\")\n",
    "print(\"Dữ liệu đã được lưu vào: X_train_onehot.csv, X_test_onehot.csv, X_train_label.csv, X_test_label.csv, y_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Luồng B: Autoencoder\n",
    "* Mục tiêu:\n",
    "  1. Xây dựng kiến trúc autoencoder: Tạo mô hình encoder-bottleneck-decoder để nén dữ liệu categorical đã mã hóa thành 32 chiều.\n",
    "  2. Huấn luyện autoencoder: Dùng hàm mất mát MSE, optimizer Adam, tăng số epochs lên 100, và thêm early stopping để tránh overfitting.\n",
    "  3. Trích xuất vector đặc trưng: Lấy output từ lớp bottleneck làm bộ đặc trưng mới.\n",
    "  4. Kết quả: Tạo X_train_autoencoder, X_test_autoencoder, y_train_autoencoder (không có y_test_autoencoder do test.csv thiếu 'class')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T15:11:28.239352Z",
     "iopub.status.busy": "2025-09-22T15:11:28.238636Z",
     "iopub.status.idle": "2025-09-22T15:12:22.089855Z",
     "shell.execute_reply": "2025-09-22T15:12:22.089141Z",
     "shell.execute_reply.started": "2025-09-22T15:11:28.239309Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout  # Thêm Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Kiểm tra cột trong test_df\n",
    "print(\"Cột trong test_df:\", list(test_df.columns))\n",
    "\n",
    "# 1. Xử lý missing values\n",
    "train_df['stalk-root'] = train_df['stalk-root'].replace('?', train_df['stalk-root'].mode()[0])\n",
    "test_df['stalk-root'] = test_df['stalk-root'].replace('?', test_df['stalk-root'].mode()[0])\n",
    "\n",
    "# 2. Loại bỏ cột không cần thiết\n",
    "columns_to_drop = ['veil-type', 'veil-color', 'id']\n",
    "columns_to_drop = [col for col in columns_to_drop if col in train_df.columns]\n",
    "train_df = train_df.drop(columns=columns_to_drop)\n",
    "test_df = test_df.drop(columns=[col for col in columns_to_drop if col in test_df.columns])\n",
    "\n",
    "# 3. Tách features và target\n",
    "X_train = train_df.drop('class', axis=1)\n",
    "y_train = train_df['class']\n",
    "X_test = test_df  # test_df không có cột 'class'\n",
    "\n",
    "# 4. Mã hóa categorical features bằng One-Hot Encoding\n",
    "ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "X_train_encoded = ohe.fit_transform(X_train)\n",
    "X_test_encoded = ohe.transform(X_test)\n",
    "\n",
    "# Lấy tên cột\n",
    "feature_names = ohe.get_feature_names_out(X_train.columns)\n",
    "X_train_encoded = pd.DataFrame(X_train_encoded, columns=feature_names)\n",
    "X_test_encoded = pd.DataFrame(X_test_encoded, columns=feature_names)\n",
    "\n",
    "# Mã hóa target\n",
    "y_train = y_train.map({'e': 0, 'p': 1})\n",
    "\n",
    "# 5. Xây dựng kiến trúc autoencoder\n",
    "input_dim = X_train_encoded.shape[1]\n",
    "encoding_dim = 32  # Có thể tăng lên 64 nếu muốn giữ thêm thông tin\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoded = Dense(64, activation='relu')(input_layer)\n",
    "# encoded = Dropout(0.2)(encoded)  # Uncomment nếu muốn giảm overfitting\n",
    "encoded = Dense(encoding_dim, activation='relu')(encoded)  # Bottleneck\n",
    "decoded = Dense(64, activation='relu')(encoded)\n",
    "decoded = Dense(input_dim, activation='sigmoid')(decoded)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "encoder_model = Model(inputs=input_layer, outputs=encoded)\n",
    "\n",
    "autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse')  # Có thể giảm xuống 0.0001 nếu loss dao động\n",
    "\n",
    "# 6. Thêm EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)  # Có thể tăng patience=15 nếu cần\n",
    "\n",
    "# 7. Huấn luyện autoencoder\n",
    "history = autoencoder.fit(X_train_encoded, X_train_encoded,\n",
    "                         epochs=100,  # Có thể tăng lên 150 nếu cần thêm thời gian học\n",
    "                         batch_size=32,  # Có thể tăng lên 64 nếu cần ổn định gradient\n",
    "                         validation_data=(X_test_encoded, X_test_encoded),\n",
    "                         callbacks=[early_stopping],\n",
    "                         verbose=1)\n",
    "\n",
    "# 8. Trích xuất đặc trưng từ bottleneck\n",
    "X_train_autoencoder = encoder_model.predict(X_train_encoded)\n",
    "X_test_autoencoder = encoder_model.predict(X_test_encoded)\n",
    "\n",
    "# Chuyển thành DataFrame\n",
    "X_train_autoencoder = pd.DataFrame(X_train_autoencoder, columns=[f'feature_{i}' for i in range(encoding_dim)])\n",
    "X_test_autoencoder = pd.DataFrame(X_test_autoencoder, columns=[f'feature_{i}' for i in range(encoding_dim)])\n",
    "\n",
    "# 9. Lưu dữ liệu\n",
    "X_train_autoencoder.to_csv('X_train_autoencoder.csv', index=False)\n",
    "X_test_autoencoder.to_csv('X_test_autoencoder.csv', index=False)\n",
    "y_train.to_csv('y_train_autoencoder.csv', index=False)\n",
    "\n",
    "# 10. Vẽ loss curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Autoencoder Loss Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.legend()\n",
    "plt.savefig('autoencoder_loss_curve.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"=== Kết quả Luồng B ===\")\n",
    "print(f\"X_train_autoencoder shape: {X_train_autoencoder.shape}\")\n",
    "print(f\"X_test_autoencoder shape: {X_test_autoencoder.shape}\")\n",
    "print(\"Dữ liệu đã được lưu vào: X_train_autoencoder.csv, X_test_autoencoder.csv, y_train_autoencoder.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bước 3: Huấn luyện Mô hình\n",
    "* Mục tiêu:\n",
    "  1. Áp dụng các thuật toán học máy truyền thống (Decision Tree, Random Forest, Logistic Regression, SVM) và mở rộng sang ensemble (XGBoost, LightGBM) để huấn luyện mô hình phân loại nhị phân (edible vs poisonous).\n",
    "  2. Train riêng biệt trên dữ liệu từ Luồng A (One-Hot Encoding và Label Encoding) và Luồng B (Autoencoder features).\n",
    "  3. Sử dụng train/validation split (80/20) từ train set để đánh giá, vì test set không có nhãn (y_test).\n",
    "  4. Tính các chỉ số phù hợp cho phân loại: Accuracy, Precision, Recall, F1, ROC-AUC.\n",
    "  5. Lập bảng so sánh hiệu suất giữa các mô hình và các luồng để xác định mô hình/luồng tốt nhất.\n",
    "  6. Dự đoán nhãn cho test set và lưu kết quả."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huấn luyện cho Luồng A (One-Hot Encoding và Label Encoding)\n",
    "* Mục tiêu: Huấn luyện và đánh giá các mô hình (Decision Tree, Random Forest, Logistic Regression, SVM, XGBoost, LightGBM) trên dữ liệu từ Luồng A, bao gồm cả One-Hot Encoding và Label Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T15:12:32.981650Z",
     "iopub.status.busy": "2025-09-22T15:12:32.980919Z",
     "iopub.status.idle": "2025-09-22T15:12:52.144387Z",
     "shell.execute_reply": "2025-09-22T15:12:52.143680Z",
     "shell.execute_reply.started": "2025-09-22T15:12:32.981625Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ===================== 3A: Luồng A – One-Hot & Label (giữ nguyên metrics + CM, sửa submission) =====================\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ===================== I/O helpers =====================\n",
    "def smart_read_csv(candidates):\n",
    "    \"\"\"Đọc CSV từ danh sách đường dẫn ứng viên (trả về df đầu tiên đọc được).\"\"\"\n",
    "    for p in candidates:\n",
    "        if p and os.path.exists(p):\n",
    "            try:\n",
    "                return pd.read_csv(p)\n",
    "            except Exception:\n",
    "                pass\n",
    "    return None\n",
    "\n",
    "def get_test_ids():\n",
    "    test_df = smart_read_csv([\n",
    "        \"/kaggle/working/test.csv\",\n",
    "        \"./test.csv\",\n",
    "        \"/mnt/data/test.csv\",\n",
    "        \"/kaggle/input/mushroom-classification-btl/test.csv\",\n",
    "    ])\n",
    "    if test_df is not None:\n",
    "        if 'id' in test_df.columns:\n",
    "            return test_df['id']               # giữ nguyên chữ thường\n",
    "        if 'Id' in test_df.columns:\n",
    "            return test_df['Id'].rename('id')  # ép về chữ thường\n",
    "    return None\n",
    "\n",
    "# ===================== Chuẩn hoá nhãn cho phần đánh giá =====================\n",
    "def _to_binary(y):\n",
    "    \"\"\"Chuẩn hoá nhãn về 0/1. Hỗ trợ y là 0/1 hoặc 'e'/'p'.\"\"\"\n",
    "    s = pd.Series(y)\n",
    "    uniq = set(s.unique())\n",
    "    if uniq <= {0, 1}:\n",
    "        return s.astype(int)\n",
    "    mapping = {'e': 0, 'p': 1, 'E': 0, 'P': 1}\n",
    "    out = s.map(mapping)\n",
    "    if out.isna().any():\n",
    "        raise ValueError(f\"Nhãn không thuộc {{0,1,'e','p'}}: {sorted(list(uniq))[:5]}\")\n",
    "    return out.astype(int)\n",
    "\n",
    "def _pos_index_for_proba(model):\n",
    "    \"\"\"Lấy index của lớp dương trong predict_proba theo model.classes_.\"\"\"\n",
    "    if hasattr(model, \"classes_\"):\n",
    "        classes = list(model.classes_)\n",
    "        if 'p' in classes:  # ưu tiên lớp 'p' nếu học trực tiếp e/p\n",
    "            return classes.index('p')\n",
    "        if 1 in classes:    # nếu học nhị phân 0/1 thì lấy lớp 1\n",
    "            return classes.index(1)\n",
    "        try:\n",
    "            return classes.index(max(classes))\n",
    "        except Exception:\n",
    "            return -1\n",
    "    return 1\n",
    "\n",
    "# ===================== Load features/labels =====================\n",
    "X_train_onehot = pd.read_csv('/kaggle/working/X_train_onehot.csv')\n",
    "X_test_onehot  = pd.read_csv('/kaggle/working/X_test_onehot.csv')\n",
    "y_train        = pd.read_csv('/kaggle/working/y_train.csv')['class']  # có thể là 'e'/'p' hoặc 0/1\n",
    "\n",
    "X_train_label  = pd.read_csv('/kaggle/working/X_train_label.csv')\n",
    "X_test_label   = pd.read_csv('/kaggle/working/X_test_label.csv')\n",
    "\n",
    "# Stratified split (dùng nhãn gốc, không ép sớm để tránh lệch mapping)\n",
    "Xtr_oh, Xval_oh, ytr_oh, yval_oh = train_test_split(\n",
    "    X_train_onehot, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "Xtr_lb, Xval_lb, ytr_lb, yval_lb = train_test_split(\n",
    "    X_train_label,  y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "# ===================== Models =====================\n",
    "models = {\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'SVM': SVC(random_state=42, probability=True),\n",
    "    'XGBoost': XGBClassifier(random_state=42, eval_metric='logloss', use_label_encoder=False),\n",
    "    'LightGBM': LGBMClassifier(random_state=42, verbose=-1)\n",
    "}\n",
    "\n",
    "# ===================== Train & Evaluate =====================\n",
    "def evaluate_models(X_train, X_val, y_train, y_val, models, prefix):\n",
    "    results = {}\n",
    "\n",
    "    # chuẩn hoá nhãn y_val về 0/1 để tính metric nhất quán (0=e, 1=p)\n",
    "    y_true_bin = _to_binary(y_val)\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "        # Dự đoán nhãn và xác suất (nếu có)\n",
    "        y_pred = model.predict(X_val)\n",
    "        y_pred_bin = _to_binary(y_pred)\n",
    "\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            pos_idx = _pos_index_for_proba(model)\n",
    "            y_proba = model.predict_proba(X_val)[:, pos_idx]\n",
    "        else:\n",
    "            y_proba = None\n",
    "\n",
    "        # metrics trên nhị phân (pos = 1 = 'p')\n",
    "        res = {\n",
    "            'Accuracy':  accuracy_score(y_true_bin, y_pred_bin),\n",
    "            'Precision': precision_score(y_true_bin, y_pred_bin, zero_division=0),\n",
    "            'Recall':    recall_score(y_true_bin, y_pred_bin, zero_division=0),\n",
    "            'F1':        f1_score(y_true_bin, y_pred_bin, zero_division=0),\n",
    "            'ROC-AUC':   roc_auc_score(y_true_bin, y_proba) if y_proba is not None else 0.0\n",
    "        }\n",
    "        results[name] = res\n",
    "\n",
    "        # Log\n",
    "        print(f\"\\n[{prefix}] {name}\")\n",
    "        for k, v in res.items():\n",
    "            print(f\"  {k}: {v:.4f}\")\n",
    "\n",
    "        # Confusion matrix hiển thị e/p\n",
    "        cm = confusion_matrix(y_true_bin, y_pred_bin, labels=[0, 1])\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=['e', 'p'],\n",
    "                    yticklabels=['e', 'p'])\n",
    "        plt.title(f'Confusion Matrix - {prefix} - {name}')\n",
    "        plt.xlabel('Predicted'); plt.ylabel('True')\n",
    "        plt.tight_layout()\n",
    "        fn = f'confusion_matrix_{prefix.lower().replace(\" \", \"_\")}_{name.replace(\" \", \"_\")}.png'\n",
    "        plt.savefig(fn, dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "    # Lưu JSON kết quả (đúng pattern Bước 4 đang đọc)\n",
    "    out_json = f'stream_a_{prefix.lower().replace(\" \", \"_\")}_results.json'\n",
    "    with open(out_json, 'w') as f:\n",
    "        json.dump(results, f)\n",
    "    print(f\"\\nĐã lưu kết quả: {out_json}\")\n",
    "    return results\n",
    "\n",
    "print(\"=== Huấn luyện & Đánh giá: Luồng A - One-Hot Encoding ===\")\n",
    "res_oh = evaluate_models(Xtr_oh, Xval_oh, ytr_oh, yval_oh, models, 'One-Hot Encoding')\n",
    "\n",
    "print(\"\\n=== Huấn luyện & Đánh giá: Luồng A - Label Encoding ===\")\n",
    "res_lb = evaluate_models(Xtr_lb, Xval_lb, ytr_lb, yval_lb, models, 'Label Encoding')\n",
    "\n",
    "# ===================== So sánh nhanh với Random Forest =====================\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Luồng':    ['One-Hot Encoding', 'Label Encoding'],\n",
    "    'Accuracy': [res_oh['Random Forest']['Accuracy'], res_lb['Random Forest']['Accuracy']],\n",
    "    'F1':       [res_oh['Random Forest']['F1'],       res_lb['Random Forest']['F1']]\n",
    "}).round(4)\n",
    "print(\"\\n=== Bảng So sánh Hiệu suất (Random Forest) cho Luồng A ===\")\n",
    "print(comparison_df)\n",
    "comparison_df.to_csv('model_comparison_stream_a.csv', index=False)\n",
    "\n",
    "# ===================== Submission (NHÃN e/p theo đề mới) =====================\n",
    "print(\"\\n=== Tạo file submission cho Kaggle (id, class = 'e'/'p') ===\")\n",
    "\n",
    "# 🔒 LUÔN đọc test.csv để lấy đúng bộ và thứ tự id (tránh lệch số dòng)\n",
    "test_df = smart_read_csv([\n",
    "    \"/kaggle/input/mushroom-classification-btl/test.csv\",  # competition input\n",
    "    \"/kaggle/working/test.csv\",\n",
    "    \"./test.csv\",\n",
    "    \"/mnt/data/test.csv\",\n",
    "])\n",
    "if test_df is None:\n",
    "    raise FileNotFoundError(\"❌ Không tìm thấy/đọc được test.csv gốc.\")\n",
    "\n",
    "if 'id' in test_df.columns:\n",
    "    test_ids = test_df['id']\n",
    "elif 'Id' in test_df.columns:\n",
    "    test_ids = test_df['Id'].rename('id')\n",
    "else:\n",
    "    raise ValueError(\"❌ test.csv không có cột id/Id.\")\n",
    "\n",
    "print(f\"✅ Lấy {len(test_ids)} hàng id từ test.csv\")\n",
    "\n",
    "# Train mô hình cuối để nộp: Random Forest trên One-Hot\n",
    "rf_onehot = RandomForestClassifier(random_state=42)\n",
    "rf_onehot.fit(X_train_onehot, y_train.values.ravel())\n",
    "\n",
    "# Dự đoán NHÃN cho test (có thể là 0/1 hoặc 'e'/'p')\n",
    "pred_any = rf_onehot.predict(X_test_onehot)\n",
    "\n",
    "# Chuẩn hoá nhãn nộp về 'e'/'p'\n",
    "if set(pd.Series(pred_any).unique()) <= {0, 1}:\n",
    "    pred_cls = np.where(pred_any == 1, 'p', 'e')\n",
    "else:\n",
    "    pred_cls = pd.Series(pred_any).astype(str).str.lower()\n",
    "    ok = pred_cls.isin(['e','p']).all()\n",
    "    if not ok:\n",
    "        raise ValueError(\"❌ Dự đoán không thuộc {'e','p'} hoặc {0,1}. Kiểm tra lại pipeline/labels.\")\n",
    "\n",
    "# Tạo submission.csv đúng format (số dòng = số dòng test)\n",
    "submission = pd.DataFrame({'id': test_ids.values, 'class': pred_cls})\n",
    "assert len(submission) == len(test_df), f\"Số dòng lệch: submission={len(submission)} vs test={len(test_df)}\"\n",
    "\n",
    "# Ghi file (không có dấu nháy kép)\n",
    "submission.to_csv('submission.csv', index=False, quoting=csv.QUOTE_NONE, escapechar='\\\\')\n",
    "print(\"✅ ĐÃ TẠO FILE NỘP: submission.csv  (cột id, class = 'e'/'p')\")\n",
    "print(submission.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huấn luyện cho Luồng B (Autoencoder)\n",
    "* Mục tiêu: Huấn luyện và đánh giá các mô hình (Decision Tree, Random Forest, Logistic Regression, SVM, XGBoost, LightGBM) trên dữ liệu từ Luồng B (Autoencoder features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ====== 3B: Luồng B – Autoencoder (Classification, output e/p) ======\n",
    "import os, json, csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def smart_read_csv(candidates):\n",
    "    for p in candidates:\n",
    "        if p and os.path.exists(p):\n",
    "            try:\n",
    "                return pd.read_csv(p)\n",
    "            except Exception:\n",
    "                pass\n",
    "    return None\n",
    "\n",
    "def _to_binary(y):\n",
    "    \"\"\"Chuẩn hoá nhãn về 0/1. Hỗ trợ y là 0/1 hoặc 'e'/'p'.\"\"\"\n",
    "    s = pd.Series(y)\n",
    "    uniq = set(s.unique())\n",
    "    if uniq <= {0, 1}:\n",
    "        return s.astype(int)\n",
    "    mapping = {'e': 0, 'p': 1, 'E': 0, 'P': 1}\n",
    "    out = s.map(mapping)\n",
    "    if out.isna().any():\n",
    "        raise ValueError(f\"Nhãn không thuộc {{0,1,'e','p'}}: {sorted(list(uniq))[:5]}\")\n",
    "    return out.astype(int)\n",
    "\n",
    "def _pos_index_for_proba(model):\n",
    "    \"\"\"Lấy index của lớp dương trong predict_proba theo model.classes_.\"\"\"\n",
    "    if hasattr(model, \"classes_\"):\n",
    "        classes = list(model.classes_)\n",
    "        if 'p' in classes:\n",
    "            return classes.index('p')\n",
    "        if 1 in classes:\n",
    "            return classes.index(1)\n",
    "        try:\n",
    "            return classes.index(max(classes))\n",
    "        except Exception:\n",
    "            return -1\n",
    "    return 1\n",
    "\n",
    "# ---------- Load ----------\n",
    "X_train_auto = pd.read_csv(\"/kaggle/working/X_train_autoencoder.csv\")\n",
    "X_test_auto  = pd.read_csv(\"/kaggle/working/X_test_autoencoder.csv\")\n",
    "y_train_auto = pd.read_csv(\"/kaggle/working/y_train_autoencoder.csv\")[\"class\"]  # 'e'/'p' hoặc 0/1\n",
    "\n",
    "Xtr_a, Xval_a, ytr_a, yval_a = train_test_split(\n",
    "    X_train_auto, y_train_auto, test_size=0.2, random_state=42, stratify=y_train_auto\n",
    ")\n",
    "\n",
    "# ---------- Models ----------\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=1000),\n",
    "    \"SVM\": SVC(random_state=42, probability=True),\n",
    "    \"XGBoost\": XGBClassifier(random_state=42, eval_metric=\"mlogloss\", use_label_encoder=False),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=42, verbose=-1),\n",
    "}\n",
    "\n",
    "# ---------- Train & Evaluate ----------\n",
    "def evaluate_models(X_train, X_val, y_train, y_val, models, prefix):\n",
    "    results = {}\n",
    "    y_true_bin = _to_binary(y_val)  # 0=e, 1=p\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "        y_pred = model.predict(X_val)\n",
    "        y_pred_bin = _to_binary(y_pred)\n",
    "\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            pos_idx = _pos_index_for_proba(model)\n",
    "            y_proba = model.predict_proba(X_val)[:, pos_idx]\n",
    "        else:\n",
    "            y_proba = None\n",
    "\n",
    "        res = {\n",
    "            \"Accuracy\":  accuracy_score(y_true_bin, y_pred_bin),\n",
    "            \"Precision\": precision_score(y_true_bin, y_pred_bin, zero_division=0),\n",
    "            \"Recall\":    recall_score(y_true_bin, y_pred_bin, zero_division=0),\n",
    "            \"F1\":        f1_score(y_true_bin, y_pred_bin, zero_division=0),\n",
    "            \"ROC-AUC\":   roc_auc_score(y_true_bin, y_proba) if y_proba is not None else 0.0,\n",
    "        }\n",
    "        results[name] = res\n",
    "\n",
    "        print(f\"\\n[{prefix}] {name}\")\n",
    "        for k, v in res.items():\n",
    "            print(f\"  {k}: {v:.4f}\")\n",
    "\n",
    "        cm = confusion_matrix(y_true_bin, y_pred_bin, labels=[0,1])\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                    xticklabels=[\"e\",\"p\"], yticklabels=[\"e\",\"p\"])\n",
    "        plt.title(f\"Confusion Matrix - {prefix} - {name}\")\n",
    "        plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
    "        plt.tight_layout()\n",
    "        fn = f'confusion_matrix_{prefix.lower().replace(\" \", \"_\")}_{name.replace(\" \", \"_\")}.png'\n",
    "        plt.savefig(fn, dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "    out_json = f'stream_b_{prefix.lower().replace(\" \", \"_\")}_results.json'\n",
    "    with open(out_json, \"w\") as f:\n",
    "        json.dump(results, f)\n",
    "    print(f\"\\nĐã lưu kết quả: {out_json}\")\n",
    "    return results\n",
    "\n",
    "print(\"=== Huấn luyện & Đánh giá cho Luồng B - Autoencoder ===\")\n",
    "results_auto = evaluate_models(Xtr_a, Xval_a, ytr_a, yval_a, models, \"Autoencoder\")\n",
    "\n",
    "# ---------- Submission (id,class = e/p) ----------\n",
    "print(\"\\n=== Dự đoán Test Set (Random Forest) & Tạo submission cho Kaggle ===\")\n",
    "\n",
    "# Đọc test.csv gốc để lấy id + số dòng chuẩn\n",
    "test_df = smart_read_csv([\n",
    "    \"/kaggle/input/mushroom-classification-btl/test.csv\",\n",
    "    \"/kaggle/working/test.csv\",\n",
    "    \"./test.csv\",\n",
    "    \"/mnt/data/test.csv\",\n",
    "])\n",
    "if test_df is None:\n",
    "    raise FileNotFoundError(\"❌ Không tìm thấy file test.csv gốc.\")\n",
    "\n",
    "if \"id\" in test_df.columns:\n",
    "    test_ids = test_df[\"id\"]\n",
    "elif \"Id\" in test_df.columns:\n",
    "    test_ids = test_df[\"Id\"].rename(\"id\")\n",
    "else:\n",
    "    raise ValueError(\"❌ test.csv không có cột id/Id.\")\n",
    "\n",
    "print(f\"✅ Lấy {len(test_ids)} hàng id từ test.csv\")\n",
    "\n",
    "# Train lại Random Forest trên toàn bộ dữ liệu Autoencoder\n",
    "best_model_auto = RandomForestClassifier(random_state=42)\n",
    "best_model_auto.fit(X_train_auto, y_train_auto.values.ravel())\n",
    "pred_any = best_model_auto.predict(X_test_auto)\n",
    "\n",
    "# Chuẩn hoá nhãn -> e/p\n",
    "if set(pd.Series(pred_any).unique()) <= {0,1}:\n",
    "    pred_cls = np.where(pred_any==1, \"p\", \"e\")\n",
    "else:\n",
    "    pred_cls = pd.Series(pred_any).astype(str).str.lower()\n",
    "    if not pred_cls.isin([\"e\",\"p\"]).all():\n",
    "        raise ValueError(\"❌ Dự đoán không hợp lệ, phải thuộc {'e','p'} hoặc {0,1}.\")\n",
    "\n",
    "# Tạo submission.csv đúng format\n",
    "submission = pd.DataFrame({\"id\": test_ids.values, \"class\": pred_cls})\n",
    "assert len(submission) == len(test_df), f\"Số dòng lệch: submission={len(submission)} vs test={len(test_df)}\"\n",
    "\n",
    "submission.to_csv(\"submission_auto.csv\", index=False, quoting=csv.QUOTE_NONE, escapechar=\"\\\\\")\n",
    "print(\"✅ ĐÃ TẠO FILE NỘP: submission_auto.csv (cột id,class = e/p)\")\n",
    "print(submission.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bước 4: Đánh giá và Phân tích Kết quả\n",
    "* Mục tiêu:\n",
    "  1. Sử dụng các chỉ số phù hợp để đánh giá hiệu suất mô hình:\n",
    "     1. Đối với phân loại (edible vs poisonous): Accuracy, Precision, Recall, F1, ROC-AUC.\n",
    "     2. Đối với hồi quy (nếu có): RMSE, MAE, R² (không áp dụng trong trường hợp này vì bài toán là phân loại).\n",
    "  2. Lập bảng so sánh hiệu suất giữa hai luồng đặc trưng (Luồng A: One-Hot Encoding và Label Encoding; Luồng B: Autoencoder) để xác định luồng nào hiệu quả hơn.\n",
    "  3. Phân tích kết quả để rút ra nhận định về chất lượng đặc trưng và hiệu quả của các mô hình, đồng thời đề xuất cải tiến nếu cần (nếu có dấu hiệu bất thường như overfitting hoặc data leakage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "# --- Cấu hình tìm file ---\n",
    "SEARCH_DIRS = ['.', '/kaggle/working', '/mnt/data']\n",
    "\n",
    "# Map prefix hợp lệ -> các tên file có thể (đảm bảo tương thích với Bước 3)\n",
    "CANDIDATE_JSON_NAMES = {\n",
    "    'stream_a_one-hot_encoding': ['stream_a_one-hot_encoding_results.json'],\n",
    "    'stream_a_label_encoding':   ['stream_a_label_encoding_results.json'],\n",
    "    'stream_b_autoencoder':      ['stream_b_autoencoder_results.json'],\n",
    "}\n",
    "\n",
    "def _find_existing_file(candidates):\n",
    "    \"\"\"\n",
    "    Tìm file trong SEARCH_DIRS theo danh sách tên 'candidates'.\n",
    "    Trả về path nếu tìm thấy, ngược lại None.\n",
    "    \"\"\"\n",
    "    for d in SEARCH_DIRS:\n",
    "        for name in candidates:\n",
    "            path = os.path.join(d, name)\n",
    "            if os.path.exists(path):\n",
    "                return path\n",
    "    return None\n",
    "\n",
    "def load_results(file_or_prefix):\n",
    "    \"\"\"\n",
    "    - Nếu truyền đường dẫn .json: dùng trực tiếp.\n",
    "    - Nếu truyền prefix (ví dụ: 'stream_a_one-hot_encoding'):\n",
    "        + Thử các tên file ứng với prefix trong CANDIDATE_JSON_NAMES\n",
    "        + Tìm trong SEARCH_DIRS\n",
    "    Trả về dict {model: {Accuracy, Precision, Recall, F1, ROC-AUC}} hoặc None.\n",
    "    \"\"\"\n",
    "    # TH1: truyền trực tiếp đường dẫn .json\n",
    "    if isinstance(file_or_prefix, str) and file_or_prefix.endswith('.json'):\n",
    "        file_path = file_or_prefix if os.path.exists(file_or_prefix) else None\n",
    "        if file_path is None:\n",
    "            print(f\"File {file_or_prefix} không tồn tại.\")\n",
    "            return None\n",
    "    else:\n",
    "        # TH2: truyền prefix\n",
    "        prefix = file_or_prefix\n",
    "        # Nếu không có trong map, vẫn thử ghép _results.json\n",
    "        candidates = CANDIDATE_JSON_NAMES.get(prefix, [f\"{prefix}_results.json\"])\n",
    "        file_path = _find_existing_file(candidates)\n",
    "        if file_path is None:\n",
    "            tried = [os.path.join(d, n) for d in SEARCH_DIRS for n in candidates]\n",
    "            print(\"Không tìm thấy file kết quả cho prefix:\", prefix)\n",
    "            print(\"Đã thử các đường dẫn sau:\")\n",
    "            for t in tried:\n",
    "                print(\"  -\", t)\n",
    "            return None\n",
    "\n",
    "    # Đọc JSON\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Lỗi giải mã JSON trong file {file_path}. Hãy kiểm tra hoặc chạy lại huấn luyện.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi mở {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Chuẩn hóa cấu trúc\n",
    "    if isinstance(data, dict) and all(isinstance(v, dict) for v in data.values()):\n",
    "        return data\n",
    "    elif isinstance(data, dict):\n",
    "        results = {}\n",
    "        for model, metrics in data.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                results[model] = metrics\n",
    "            else:\n",
    "                results[model] = {'Accuracy': 0, 'Precision': 0, 'Recall': 0, 'F1': 0, 'ROC-AUC': 0}\n",
    "        return results\n",
    "    else:\n",
    "        print(f\"Cấu trúc file {file_path} không hợp lệ.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# ====== TẢI KẾT QUẢ (dùng đúng prefix) ======\n",
    "results_stream_a_onehot = load_results('stream_a_one-hot_encoding')\n",
    "results_stream_a_label  = load_results('stream_a_label_encoding')\n",
    "results_stream_b_auto   = load_results('stream_b_autoencoder')\n",
    "\n",
    "# Kiểm tra thiếu\n",
    "missing = []\n",
    "if results_stream_a_onehot is None:\n",
    "    missing.append('stream_a_one-hot_encoding_results.json')\n",
    "if results_stream_a_label is None:\n",
    "    missing.append('stream_a_label_encoding_results.json')\n",
    "if results_stream_b_auto is None:\n",
    "    missing.append('stream_b_autoencoder_results.json')\n",
    "\n",
    "if missing:\n",
    "    print(\"\\nLỗi: Thiếu file JSON kết quả sau:\")\n",
    "    for m in missing:\n",
    "        print(\"  -\", m)\n",
    "    print(\"\\nGợi ý khắc phục:\")\n",
    "    print(\"- Đảm bảo đã CHẠY xong Bước 3 và các file trên đã được tạo.\")\n",
    "    print(\"- Nếu bạn không chạy trên Kaggle, hãy kiểm tra thư mục hiện tại hoặc /mnt/data.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# ====== TẠO BẢNG SO SÁNH ======\n",
    "def create_comparison_df(results, prefix):\n",
    "    rows = []\n",
    "    for model, metrics in results.items():\n",
    "        rows.append({\n",
    "            'Luồng': prefix,\n",
    "            'Mô hình': model,\n",
    "            'Accuracy': metrics.get('Accuracy', 0),\n",
    "            'Precision': metrics.get('Precision', 0),\n",
    "            'Recall': metrics.get('Recall', 0),\n",
    "            'F1': metrics.get('F1', 0),\n",
    "            'ROC-AUC': metrics.get('ROC-AUC', 0)\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_stream_a_onehot = create_comparison_df(results_stream_a_onehot, 'Luồng A - One-Hot Encoding')\n",
    "df_stream_a_label  = create_comparison_df(results_stream_a_label, 'Luồng A - Label Encoding')\n",
    "df_stream_b_auto   = create_comparison_df(results_stream_b_auto,  'Luồng B - Autoencoder')\n",
    "\n",
    "combined_df = pd.concat([df_stream_a_onehot, df_stream_a_label, df_stream_b_auto], ignore_index=True)\n",
    "\n",
    "print(\"\\n=== Bảng So sánh Hiệu suất Chi tiết giữa Luồng A và Luồng B ===\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(combined_df.round(4))\n",
    "pd.reset_option('display.max_columns')\n",
    "\n",
    "# Lưu\n",
    "out_csv = 'combined_model_comparison_detailed.csv'\n",
    "combined_df.to_csv(out_csv, index=False)\n",
    "print(f\"\\nĐã lưu bảng tổng hợp: {out_csv}\")\n",
    "\n",
    "# ====== VẼ BIỂU ĐỒ F1 ======\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Mô hình', y='F1', hue='Luồng', data=combined_df, palette='viridis')\n",
    "plt.title('So sánh F1 Score giữa Luồng A và Luồng B theo Mô hình')\n",
    "plt.xlabel('Mô hình')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(title='Luồng')\n",
    "plt.tight_layout()\n",
    "plt.savefig('f1_comparison_plot.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# ====== PHÂN TÍCH ======\n",
    "print(\"\\n=== Phân tích Kết quả ===\")\n",
    "print(\"1) Nếu các chỉ số đều ~1.0, nhiều khả năng dữ liệu xác thực quá dễ hoặc có rò rỉ dữ liệu (data leakage).\")\n",
    "print(\"2) Kiểm tra các ảnh confusion_matrix_*.png để xác thực phân phối dự đoán.\")\n",
    "print(\"3) Nếu nghi ngờ overfitting hoặc leakage, thử đổi random_state/cách chia data hoặc dùng cross-validation.\")\n",
    "print(\"4) Chọn mô hình/luồng có F1 cao nhất cho suy diễn test (test_predictions_*.csv).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bước 5: So sánh và Kết luận\n",
    "\n",
    "📌 **Lưu ý của đề bài**  \n",
    "- Chỉ sử dụng **dữ liệu được cung cấp** (không dùng external data).  \n",
    "- Sinh viên phải mô tả rõ ràng các bước xử lý, lựa chọn thuật toán, tham số.  \n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Phân tích Luồng A – Kỹ thuật truyền thống (One-Hot & Label Encoding)\n",
    "\n",
    "**Ưu điểm**\n",
    "- **Đơn giản, dễ hiểu, dễ triển khai**  \n",
    "  → Vì chỉ dùng các kỹ thuật cơ bản trong sklearn (OneHotEncoder, LabelEncoder), không cần mô hình phức tạp hay GPU.  \n",
    "- **Kết quả minh bạch, dễ giải thích**  \n",
    "  → Mỗi cột one-hot thể hiện rõ một giá trị của đặc trưng (ví dụ: “odor = foul”), nên dễ liên hệ trực tiếp đến ý nghĩa thực tế.  \n",
    "- **Hiệu quả cho dữ liệu phân loại mạnh**  \n",
    "  → Với bài toán nấm, các đặc trưng phân loại như `odor`, `spore-print-color`, `gill-color` vốn tách biệt rõ edible/poisonous, nên one-hot đã đủ mạnh để phân loại gần như hoàn hảo.  \n",
    "- **Hỗ trợ feature engineering thủ công**  \n",
    "  → Người dùng có thể chủ động tạo đặc trưng mới (interaction features) dựa trên kiến thức miền, điều mà embedding tự động khó đảm bảo.\n",
    "\n",
    "**Nhược điểm**\n",
    "- **One-Hot Encoding làm tăng số chiều dữ liệu**  \n",
    "  → Vì mỗi giá trị của đặc trưng lại sinh ra một cột riêng, dẫn đến ma trận thưa và tốn RAM.  \n",
    "- **Label Encoding dễ gây sai lệch**  \n",
    "  → Vì gán số nguyên (0,1,2,...) cho các giá trị phân loại, tạo ra quan hệ thứ tự giả mạo mà mô hình tuyến tính có thể hiểu nhầm.  \n",
    "- **Khả năng biểu diễn hạn chế**  \n",
    "  → Vì chỉ phản ánh mối quan hệ tuyến tính đơn giản, khó mô hình hóa các phụ thuộc phức tạp hoặc phi tuyến giữa nhiều đặc trưng.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Phân tích Luồng B – Autoencoder\n",
    "\n",
    "**Ưu điểm**\n",
    "- **Giảm chiều dữ liệu**  \n",
    "  → Autoencoder nén dữ liệu thành vector nhỏ gọn (bottleneck), giúp các mô hình phía sau huấn luyện nhanh hơn và tránh curse of dimensionality.  \n",
    "- **Học được đặc trưng phi tuyến phức tạp**  \n",
    "  → Nhờ mạng nơ-ron nhiều lớp, autoencoder có thể khám phá mối quan hệ ẩn giữa các đặc trưng, điều mà one-hot không thể.  \n",
    "- **Embedding có thể tái sử dụng**  \n",
    "  → Vector bottleneck có thể dùng làm đầu vào cho nhiều mô hình khác nhau, giống một dạng “feature representation” chung.\n",
    "\n",
    "**Nhược điểm**\n",
    "- **Khó giải thích (mất interpretability)**  \n",
    "  → Vì mỗi chiều trong vector embedding không còn gắn với một đặc trưng gốc, nên khó trả lời “đặc trưng nào ảnh hưởng nhiều nhất”.  \n",
    "- **Chi phí huấn luyện cao**  \n",
    "  → Cần nhiều epoch, tuning siêu tham số và thường phải chạy trên GPU, phức tạp hơn nhiều so với encoding truyền thống.  \n",
    "- **Nhạy cảm với tham số**  \n",
    "  → Các yếu tố như số tầng, số neuron, learning rate… ảnh hưởng lớn đến chất lượng embedding. Nếu tuning không tốt dễ dẫn đến underfitting hoặc overfitting.  \n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Kết luận và Khuyến nghị\n",
    "\n",
    "1. **Kết quả thực nghiệm**:  \n",
    "   - Luồng A (đặc biệt One-Hot Encoding) đạt Accuracy/F1 ≈ 1.0 → mô hình phân loại gần như hoàn hảo.  \n",
    "   - Luồng B cũng cho kết quả tốt, nhưng không vượt trội, trong khi chi phí và độ phức tạp cao hơn.  \n",
    "\n",
    "2. **So sánh tổng thể**:  \n",
    "   - Bài toán nấm vốn có đặc trưng phân loại mạnh và tách biệt rõ ràng → one-hot encoding đủ để khai thác triệt để thông tin.  \n",
    "   - Autoencoder tuy hiện đại nhưng không mang lại lợi ích rõ rệt trong bối cảnh này.  \n",
    "\n",
    "3. **Khuyến nghị cuối cùng**:  \n",
    "   - Chọn **Luồng A – One-Hot Encoding** cho triển khai thực tế: vì đạt hiệu suất cao, dễ hiểu, dễ áp dụng và ít tốn tài nguyên.  \n",
    "   - Giữ **Luồng B – Autoencoder** làm hướng nghiên cứu mở rộng: khi dữ liệu trở nên lớn hơn, nhiều đặc trưng hơn, hoặc cần giảm chiều để kết hợp với mô hình phức tạp.  \n",
    "\n",
    "---\n",
    "\n",
    "### 📌 Giải thích ngắn gọn\n",
    "Autoencoder có ưu thế trong việc **nén thông tin** và khám phá quan hệ phức tạp, nhưng đánh đổi bằng **mất tính diễn giải và chi phí cao**. Trong khi đó, One-Hot Encoding vừa **đơn giản, minh bạch, hiệu quả**, lại cho kết quả gần như hoàn hảo trong bài toán phân loại nấm. Vì thế, lựa chọn hợp lý nhất cho bài toán này là **Luồng A**.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ sklearn version: 1.6.1\n",
      "Accuracy: 1.0\n",
      "F1 (pos='p'): 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           e     1.0000    1.0000    1.0000       631\n",
      "           p     1.0000    1.0000    1.0000       588\n",
      "\n",
      "    accuracy                         1.0000      1219\n",
      "   macro avg     1.0000    1.0000    1.0000      1219\n",
      "weighted avg     1.0000    1.0000    1.0000      1219\n",
      "\n",
      "💾 Saved: C:\\Users\\Duy Tiến\\Desktop\\btl\\mushroom_pipeline.joblib\n"
     ]
    }
   ],
   "source": [
    "# train_and_save.py\n",
    "import joblib, pandas as pd\n",
    "from pathlib import Path\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "TRAIN_CSV = \"Dataset\\\\train.csv\"                             # sửa đường dẫn nếu cần\n",
    "OUT_PATH  = Path(\"mushroom_pipeline.joblib\")    # app sẽ load file này\n",
    "\n",
    "def main():\n",
    "    print(\"✅ sklearn version:\", sklearn.__version__)  # phải là 1.6.1\n",
    "    df = pd.read_csv(TRAIN_CSV)\n",
    "    assert \"class\" in df.columns, \"train.csv cần cột 'class' (e/p).\"\n",
    "    y = df[\"class\"].astype(str).str.lower()          # 'e'/'p'\n",
    "    X = df.drop(columns=[\"class\"])\n",
    "\n",
    "    cat_cols = [c for c in X.columns if X[c].dtype == \"object\"]\n",
    "    num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "    pre = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), cat_cols),\n",
    "            # có thể thêm xử lý số nếu cần, ví dụ StandardScaler cho num_cols\n",
    "        ],\n",
    "        remainder=\"passthrough\"\n",
    "    )\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1)\n",
    "    pipe = Pipeline([(\"prep\", pre), (\"clf\", clf)])\n",
    "\n",
    "    # Train/val để xem chất lượng\n",
    "    Xtr, Xval, ytr, yval = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    pipe.fit(Xtr, ytr)\n",
    "    pred = pipe.predict(Xval)\n",
    "    print(\"Accuracy:\", accuracy_score(yval, pred))\n",
    "    print(\"F1 (pos='p'):\", f1_score(yval, pred, pos_label=\"p\"))\n",
    "    print(classification_report(yval, pred, digits=4))\n",
    "\n",
    "    # Fit toàn bộ & lưu\n",
    "    pipe.fit(X, y)\n",
    "    OUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "    joblib.dump(\n",
    "        {\n",
    "            \"pipeline\": pipe,\n",
    "            \"feature_cols\": X.columns.tolist(),\n",
    "            \"cat_cols\": cat_cols,\n",
    "            \"num_cols\": num_cols,\n",
    "            \"target_labels\": [\"e\", \"p\"],\n",
    "        },\n",
    "        OUT_PATH\n",
    "    )\n",
    "    print(\"💾 Saved:\", OUT_PATH.resolve())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 13804480,
     "isSourceIdPinned": false,
     "sourceId": 115654,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
